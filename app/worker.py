# app/worker.py
import asyncio
import json
import logging
import os
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø–∞–∫–µ—Ç app
sys.path.append(os.getcwd())

from aiokafka import AIOKafkaConsumer
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.settings import settings
from app.database import SessionLocal
from app.services.rag import process_document

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - [WORKER] - %(levelname)s - %(message)s"
)
logger = logging.getLogger("WORKER")


async def process_document_event(data: dict):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    """
    doc_id = data.get("doc_id")
    file_path = data.get("file_path")

    if not doc_id or not file_path:
        logger.error("Invalid document event data")
        return

    logger.info(f"üöÄ Starting RAG processing for Document ID {doc_id}...")

    # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Å–µ—Å—Å–∏—é –ë–î –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞
    async with SessionLocal() as db:
        try:
            # –í—ã–∑—ã–≤–∞–µ–º —Ç—É —Å–∞–º—É—é —Ç—è–∂–µ–ª—É—é —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ rag.py
            await process_document(db, file_path, doc_id)
            logger.info(f"‚úÖ Document {doc_id} processed successfully.")
        except Exception as e:
            logger.error(f"‚ùå Error processing document {doc_id}: {e}")


async def process_task_event(data: dict):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π).
    """
    task_id = data.get("task_id")
    title = data.get("title")
    logger.info(f"üîî New Task Event received: ID {task_id} - '{title}'. Sending notifications...")
    # –¢—É—Ç –±—ã–ª–∞ –±—ã –ª–æ–≥–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ Push/Email
    await asyncio.sleep(0.5)  # –ò–º–∏—Ç–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã
    logger.info(f"‚úÖ Notifications for Task {task_id} sent.")


async def consume():
    """
    –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –≤–æ—Ä–∫–µ—Ä–∞.
    """
    logger.info(f"Starting Kafka Worker...")
    logger.info(f"Bootstrap Servers: {settings.KAFKA_BOOTSTRAP_SERVERS}")

    # –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è —Å—Ä–∞–∑—É –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–ø–∏–∫–æ–≤
    topics = [settings.KAFKA_TOPIC_DOCS, settings.KAFKA_TOPIC_TASKS]

    consumer = AIOKafkaConsumer(
        *topics,
        bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
        group_id="pyro_background_workers",  # –ì—Ä—É–ø–ø–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ 1 –≤–æ—Ä–∫–µ—Ä
        value_deserializer=lambda m: json.loads(m.decode('utf-8')),
        auto_offset_reset="earliest"  # –ï—Å–ª–∏ –≤–æ—Ä–∫–µ—Ä —É–ø–∞–ª, —á–∏—Ç–∞—Ç—å –Ω–µ–¥–æ—á–∏—Ç–∞–Ω–Ω–æ–µ
    )

    while True:
        try:
            await consumer.start()
            logger.info("‚úÖ Connected to Kafka!")
            break
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Kafka not ready, retrying in 5s... ({e})")
            await asyncio.sleep(5)

    try:
        async for msg in consumer:
            topic = msg.topic
            event = msg.value
            event_type = event.get("type")
            data = event.get("payload")

            logger.info(f"üì• Received [{topic}] -> {event_type}")

            # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π
            if topic == settings.KAFKA_TOPIC_DOCS and event_type == "document_uploaded":
                await process_document_event(data)

            elif topic == settings.KAFKA_TOPIC_TASKS and event_type == "task_created":
                await process_task_event(data)

    finally:
        await consumer.stop()


if __name__ == "__main__":
    asyncio.run(consume())